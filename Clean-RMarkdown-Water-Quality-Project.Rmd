---
title: "Water Quality"
output: html_document
---
# Richard Pallangyo

## Introduction

Arsenic naturally occurs in groundwater sources around the world. Arsenic contamination of groundwater affects millions of people around the world including the United States, Nicaragua, Argentina, China, Mexico, Chile, Bangladesh, India, and Vietnam, for example (Smith et al. 2000; Amini et al. 2008; Lin et al. 2017). The World Health Organization (WHO 2018a) estimates that over 140 million people in 50 countries are exposed to arsenic contaminated drinking water above the WHO guideline of 10 $\mu$g/L. Health effects of arsenic exposure include numerous types of cancer and other disorders.

This project follows an analysis of a public health study performed in rural Bangladesh (Gelman et al. 2004). In this study, wells used for drinking water were analyzed for arsenic contamination and correspondingly labeled as safe or unsafe. The study determined whether households switched the well used for drinking water and measured. Additionally, several variables where measured that were thought to possibly influence the decision of whether or not to switch wells. Here, we will investigate how accurately we can predict whether or not a household will switch wells based on these environmental variables.


## Data Collection

See Gelman et al. (2004) for a discussion of data collection. Briefly, arsenic levels were measured in Araihazar, Bangladesh during the years 1999 - 2000. Additional information was collected by a survey:
1. Whether or not the household swithed wells.
2. The distance (in meters) to the closest known safe well.
3. Whether any members of the household are involved in community organizations.
4. The highest education level in the household.

### Load necessary packages

```{r, warning=FALSE}

#skimr provides a nice summary of a data set
library(skimr)
#tidyverse contains packages we will use for processing and plotting data
library(tidyverse)
#GGally has a nice pairs plotting function
library(GGally)
#tidymodels has a nice workflow for many models. We will use it for XGBoost
library(tidymodels)
#xgboost lets us fit XGBoost models
library(xgboost)
#vip is used to visualize the importance of predicts in XGBoost models
library(vip)

#Set the plotting theme
theme_set(theme_bw())

```




Loading the data set contained in the file `wells.dat` and naming the data frame `df`.


```{r}
df <- read.table('wells.dat')
```




### Explore the contents of the data set


Look at the first few rows of the data frame.

```{r}
head(df)
```



#### Explore the columns


The variables in the data set are:

1. `switch`: An indicator of whether a household switches wells.

2. `arsenic`: The arsenic level of the household’s well.

3. `dist`: The distance (in meters) to the closest known safe well.

4. `assoc`: An indicator of whether any members of the household are involved in community organizations.

5. `educ`: The highest education level in the household.


What variable(s) do we want to predict?
We are interested in whether households switched the wells they were using after wells were labeled as either safe or unsafe, based on measured arsenic levels. So, we are trying to predict switch.


What variables are possible predictors?

We will consider the following inputs to a model:

The distance (in meters) to the closest known safe well `dist`

The arsenic level of the household’s well `arsenic`

Whether any members of the household are involved in community organizations `assoc`

The highest education level in the household `educ`


#### Rename the columns

The names of the columns in this data frame are understandable, but two of the columns, `switch` and `distance`, have the names of functions that already exist in R. It is bad practice to name your variables or functions after existing functions, so we will change them. While we are at it, we will change some other names to be complete words.


```{r}

df <- df %>% 
  rename(switch_well = "switch",
         distance = "dist",
         association = "assoc",
         education = "educ")

```




#### Convert data types for qualitative predictor

```{r}
df <- df %>% mutate(switch_well = factor(switch_well)) %>% mutate(association = factor(association))

```



## Exploratory data analysis




### Graphical summaries


Use a pairs-plot to investigate the distributions of the variables and relationships between variables. 

```{r}
ggpairs(df,lower = list(continuous = "cor", combo = "box_no_facet", discrete ="facetbar", na = "na"), upper = list(continuous = "points", combo ="facethist", discrete = "facetbar", na = "na"), progress = FALSE)
```

`arsenic` and `distance` have unimodal, positively skewed distributions.

`education` has a bimodal distribution with peaks at 0 and 5.

The distributions of `arsenic`, `distance`, and `education` do not appear to be obviously different for households that switch and do not switch wells.





#### Plot each input numerical variable vs. switch_well

We want to investigate whether the probability of switching wells is a clear function of the input numerical variables. 

Make scatter plots of `switch_well` vs. each of the input numerical variables.



Use `geom_jitter` so that you can see the density of points. Without jittering the points, many values lie on top of each other and it is difficult to visually estimate the probability of switching.




Plot `switch_well` vs. `arsenic`

```{r}
df %>% 
  ggplot(aes(x=arsenic, y=switch_well)) + 
  geom_jitter(width = 0, height = 0.1) +
  labs(x = "Arsenic level in nearest well", y = "Switch (No = 0, Yes = 1)")
```

There appears to be a slight increase in the probability of switching as the arsenic level increases, but it is not a dramatic increase


Plot `switch_well` vs. `distance`

```{r}
df %>% 
  ggplot(aes(x = distance, y = switch_well)) +
  geom_jitter(width = 0, height = 0.1) +
  labs(x = "Distance (in meters) to the nearest safe well", y = "Switch (No = 0, Yes = 1)")
```
There appears to be a slight decrease in the probability of switching as distance increases, but it is not a dramatic increase.

Plot `switch_well` vs. `education`

```{r}
df %>% 
  ggplot(aes(x = education, y = switch_well)) +
  geom_jitter(width = 0.15, height = 0.1) +
  labs(x = "Education level", y = "Switch (No = 0, Yes = 1)")
```
There appears to be a slight increase in the probability of switching as the education level increases, but it is not a dramatic increase.






## Exploratory modeling

We will build logistic regression models of increasing complexity in order to further understand the data.

### Fit a model with distance as the predictor


```{r}
fit_dist <- glm(switch_well ~ distance, family = binomial, data = df)
summary(fit_dist)
```



Fitting a logistic regression model with distance as the predictor and examining the summary. First, We will scale the distance variable to be in units of 100s of meters.

Use the `mutate` function to convert the distance units into 100s of meters.
```{r}
df <- df %>% 
  mutate(distance = distance/100)
```




Fitting the model and inspecting the summary.

```{r}
fit_dist <- logistic_reg() %>% 
  set_engine("glm") %>% 
  fit(switch_well ~ distance, data = df)

tidy(fit_dist)
```



Plotting the fitted logistic regression model along with the data.

```{r}

ggplot(df,aes(x = distance, y = as.numeric(switch_well)-1)) + 
  geom_point(position = position_jitter(0,0.02)) + 
  geom_smooth(method="glm", method.args=list(family="binomial"), se=FALSE, formula = y ~ x) + 
  labs(x = "Distance (in 100 meters) to the nearest safe well", y = "Switch (No = 0, Yes = 1)")

```


#### Interpret the coefficients


Interpret the value of $\hat{\beta}_0$.

The value of $\hat{\beta}_0$ is 0.61. When we substitute this value into the sigmoid function, the estimated probability of switching wells if the nearest safe well is where you live is 65% 


Interpret the value of $\hat{\beta}_1$ by discussing its sign and what it says about the maximum rate of change of the probability of switching.

The value of $\hat{\beta}_1$ is -0.62 and less than 0. So, an increase in distance to the nearest safe well is associated with a decrease in probability of switching wells.




### Fit a model with distance and arsenic as predictors

Fitting the model and examining the coefficients.

```{r}

fit_dist_ars <- logistic_reg() %>% 
  set_engine("glm") %>% 
  fit(switch_well ~ distance + arsenic, data = df)

tidy(fit_dist_ars)

```



#### Explore the model

Interpret the meaning of the coefficients.

The value of $\hat{\beta}_0$ is 0.002749. When we substitute this value into the sigmoid function, the estimated probability of switching wells if the nearest safe well is where you live is 50%

$\hat{\beta}_1$ is -0.896644172, which is less than 0. So, an increase in distance to the nearest safe well is associated with a decrease in probability of switching wells

$\hat{\beta}_2$ is 0.460774949, which is greater than 0. So, an increase in arsenic levels is associated with a increase in probability of switching wells.

Why did the coefficient for `distance` change when arsenic was added?
`distance` and `arsenic` predictors can be related, which means that they affect each other.

#### Visualize

Plot the decision boundary

```{r}

#Give a shorter name for the coefficients to make it easier to read
betas <- fit_dist_ars$fit$coefficients

df %>% 
  ggplot(aes(x = distance, y = arsenic, color = factor(switch_well))) +
  geom_point() +
  geom_abline(intercept = -betas[1]/betas[3], slope = -betas[2]/betas[3]) +
  labs(x = "Distance (in 100 meters) to the nearest safe well", y = "Arsenic concentration in well water", color = "Switch well") +
  scale_color_manual(labels = c("No", "Yes"), values = c("blue", "orange"))

```




## Comparing models

We will use logistic regression, XGBoost, and k-nearest neighbors to construct models that predict the probability of switching wells.

To compare the different approaches, we will use a training and testing split of the data set.

We will use the tidymodels approach for all models.

### Get train and test splits

We will split the data into training and testing sets, with 80% of the data kept for training.   

```{r}

#Do the split. Keep 80% for training. Use stratified sampling based on switch_well to keep the proportion of switches in the test and training sets to be approximately equal.
set.seed(12)
split <- initial_split(df, prop = 0.8, strata = switch_well)

#Extract the training and testing splits
df_train <- training(split)
df_test <- testing(split)

```


### Null model 

The null model prediction always predicts the value of `switch_well` that occurs most often in the training data.


What is the null model prediction for `switch_well`?

```{r}
df_train %>% 
  count(switch_well)
```
There are more households who switch in the data set, so the null model prediction is to switch wells


If we always predict that a household will switch wells, how accurate is the prediction on test data?

```{r}

null_accuracy <- sum(df_test$switch_well == 1)/length(df_test$switch_well)

null_accuracy %>% round(3)

```
We will be about 58% accurate if we predict that a household will switch wells.

This represents a baseline that other models will be compared to.





### Logistic regression model

#### Model specification

First specify a logistic regression model with the glm engine.
```{r}
log_reg_model <- logistic_reg() %>%
  set_engine("glm")
```



#### Workflow

Create a workflow that specifies the model formula to fit and add the model specification.

```{r}
log_reg_wf <- workflow() %>%
  add_formula(switch_well ~ .) %>% add_model(log_reg_model)

log_reg_wf
```


#### Fit to training data

Fit the model to the training data and explore the coefficients.


First fit the model.
```{r}
log_reg_fit <- log_reg_wf %>% fit(df_train)
```



Examine the coefficients
```{r}
tidy(log_reg_fit)
```
In the full model, `association1` and `education` are not statistically significant.

#### Predict test data

Generate predictions and bind the predictions together with the true `switch_well` values from the test data.
```{r}
predictions_log_reg <- log_reg_fit %>%
  predict(new_data = df_test) %>% 
  bind_cols(df_test %>% select(switch_well))
```

Binding the predictions and actual values together into one tibble will help us to plot the confusion matrix and to compute measures of accuracy.

#### Assess fit

Plot the confusion matrix.
```{r}
predictions_log_reg %>%
  conf_mat(switch_well, .pred_class) %>% 
  pluck(1) %>% 
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), color = "blue", alpha = 1, size = 10)
```




Get the prediction accuracy. This prediction accuracy is equal to the proportion of correct predictions in the test data set. 
```{r}
predictions_log_reg %>%
  metrics(switch_well, .pred_class) %>%
  select(-.estimator) %>%
  filter(.metric == "accuracy") %>% 
  mutate(.estimate = round(.estimate,3))
```
The logistic regression model is 63% accurate of the time.


Compare to  null model prediction
```{r}
null_accuracy %>% round(3)
```
The null model is 58% accurate of the time.


Get the sensitivity. This is the proportion of correct predictions for households that did switch wells.
```{r}
predictions_log_reg %>%
  sens(switch_well, .pred_class, event_level = "second") %>%
  select(-.estimator) %>%
  mutate(.estimate = round(.estimate,3)) 
```


Get the specificity. This is the proportion of correct predictions for households that did not switch wells.
```{r}
predictions_log_reg %>%
  spec(switch_well, .pred_class, event_level = "second") %>%
  select(-.estimator) %>%
  mutate(.estimate = round(.estimate,3))
```
Looking at the null model and logistic regression model, we are better at predicting that households will switch because there are more switches in the data set.


### XGBoost


#### Set up the model

The model will be a boosted tree model, so we start by specifying the features of a `boost_tree` model. The`boost_tree` creates a specification of a model, but does not fit the model.


First specify an XGBoost model for classification with the xgboost engine. Set`tree_depth`, `min_n`, `loss_reduction`, `sample_size`, `mtry`, and `learn_rate` as parameters to tune. Set `trees` = 1000.

```{r}
xgb_model <- boost_tree(
  mode = "classification",  #We are solving a classification problem
  trees = 1000, 
  tree_depth = tune(),  # tune() says that we will specify this parameter later
  min_n = tune(), 
  loss_reduction = tune(),                     
  sample_size = tune(), 
  mtry = tune(),         
  learn_rate = tune(),                         
  ) %>% 
  set_engine("xgboost") ## We will use xgboost to fit the model

xgb_model
```




Create a workflow that specifies the model formula and the model type. We are still setting up the model; this does not fit the model.

<details>
  <summary>**Show Answer**</summary>
```{r}

xgb_wf <- workflow() %>%
  add_formula(switch_well ~ .) %>%
  add_model(xgb_model)

xgb_wf

```
</details>
<br>


#### Fit the model

We need to fit all of the parameters that we specified as `tune()`. 


Specify the parameter grid using the function `grid_latin_hypercube`:
```{r}
xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), df_train),
  learn_rate(),
  size = 30  #Create 30 sets of the 6 parameters
)
```



Create folds for cross-validation, using stratified sampling based on `switch_well`.
```{r}
folds <- vfold_cv(df_train, strata = switch_well)
```



Do the parameter fitting. 
```{r}
xgb_grid_search <- tune_grid(
  xgb_wf,              #The workflow
  resamples = folds,   #The training data split into folds
  grid = xgb_grid,     #The grid of parameters to fit
  control = control_grid(save_pred = TRUE)
)

xgb_grid_search
```



Get the best model based on `accuracy`.
```{r}
best_xgb <- select_best(xgb_grid_search, "accuracy")
```



Update the workflow with the best parameters.
```{r}
final_xgb <- finalize_workflow(
  xgb_wf,
  best_xgb
)

final_xgb
```




#### Fit to training data

Fit the model to the training data.
```{r}
xgb_fit <- final_xgb %>% 
  fit(df_train)
```




#### Predict test data

Generate predictions and bind them together with the true values from the test data.
```{r}
predictions_xgb <- xgb_fit %>%
  predict(new_data = df_test) %>% 
  bind_cols(df_test %>% select(switch_well))
```



#### Assess fit

Plot the confusion matrix
```{r}
predictions_xgb %>%
  conf_mat(switch_well, .pred_class) %>% 
  pluck(1) %>% 
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), color = "blue", alpha = 1, size = 10)
```



Get prediction accuracy. This prediction accuracy is equal to the proportion of correct predictions in the test data set. 
```{r}
predictions_xgb %>%
  metrics(switch_well, .pred_class) %>%
  select(-.estimator) %>%
  filter(.metric == "accuracy") %>% 
  mutate(.estimate = round(.estimate,3))
```
The tree model is 65% accurate of the time.



Compare to  null model prediction
```{r}
null_accuracy %>% round(3)
```

The null model is 58% accurate of the time.



Get the sensitivity. This is the proportion of correct predictions for households that did switch wells.
```{r}
predictions_xgb %>%
  sens(switch_well, .pred_class, event_level = "second") %>%
  select(-.estimator) %>%
  mutate(.estimate = round(.estimate,3))
```



Get the specificity. This is the proportion of correct predictions for households that did not switch wells.
```{r}
predictions_xgb %>%
  spec(switch_well, .pred_class, event_level = "second") %>%
  select(-.estimator) %>%
  mutate(.estimate = round(.estimate,3))
```




#### Relative importance of predictors
Look at which predictors are most important in the model
```{r}
xgb_fit %>%
  pull_workflow_fit() %>%
  vip(geom = "col")
```




### k nearest neighbors

```{r}
knn_model <- nearest_neighbor(
    mode = "classification",
    neighbors = tune("K")
  ) %>%
  set_engine("kknn")
```


#### Model specification

First specify a k nearest neighbors model with the kknn engine.

```{r}

knn_model <- nearest_neighbor(
    mode = "classification",
    neighbors = tune("K")
  ) %>%
  set_engine("kknn")


```


#### Workflow

Create a workflow that specifies the model formula to fit and the model type.

```{r}

knn_wf <- workflow() %>%
add_formula(switch_well ~ .) %>%
  add_model(knn_model)

```


#### Fit the hyperparameter k

Specify a set of values of k to try.
```{r}

knn_grid <- parameters(knn_wf) %>%  
  update(K = neighbors(c(1, 50))) %>% 
  grid_latin_hypercube(size = 10)

knn_grid

```

Use cross validation on the previously defined folds to find the best value of k.

```{r}

knn_grid_search <- tune_grid(
  knn_wf,
  resamples = folds,
  grid = knn_grid,
  control = control_grid(save_pred = TRUE)
)

knn_grid_search
```



Get the best model based on `accuracy`.

```{r}

best_knn <- select_best(knn_grid_search, "accuracy")

```


Update the workflow with the best parameter k.

```{r}
final_knn <- finalize_workflow(
  knn_wf,
  best_knn
)

final_knn
```


#### Fit to training data

Fit the model to the training data and explore the coefficients.

First fit the model.
```{r}

knn_fit <- final_knn %>% 
  fit(df_train)

```


#### Predict test data

Generate predictions and bind together with the true values from the test data.
```{r}

predictions_knn <- knn_fit %>%
  predict(new_data = df_test) %>% 
  bind_cols(df_test %>% select(switch_well))

```


#### Assess fit

Visualize the confusion matrix

```{r}

predictions_knn %>%
  conf_mat(switch_well, .pred_class) %>% 
  pluck(1) %>% 
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), color = "blue", alpha = 1, size = 10)

```


Get prediction accuracy. This prediction accuracy is equal to the proportion of correct predictions in the test data set. 
```{r}

predictions_knn %>%
  metrics(switch_well, .pred_class) %>%
  select(-.estimator) %>%
  filter(.metric == "accuracy") %>% 
  mutate(.estimate = round(.estimate,3))
  
```
Compare to  null model prediction

```{r}

null_accuracy %>% round(3)

```
The null model is accurate 58% of the time.


Get the sensitivity. This is the proportion of correct predictions for households that did switch wells.

```{r}

predictions_knn %>%
  sens(switch_well, .pred_class, event_level = "second") %>%
  select(-.estimator) %>%
  mutate(.estimate = round(.estimate,3)) 

```

Get the specificity. This is the proportion of correct predictions for households that did not switch wells.

```{r}

predictions_knn %>%
  spec(switch_well, .pred_class, event_level = "second") %>%
  select(-.estimator) %>%
  mutate(.estimate = round(.estimate,3))

```



### Compare models

You used three methods to construct a model

1. Logistic regression
2. XGBoost
3. k nearest neighbors

Compare the performance of the models. 


Display the metrics of the models in a table format
```{r}
model_table <- matrix(c(0.633,0.851,0.339,0.646,0.874, 0.342, 0.626,0.77,0.432,0.613, 0.595, 0.616),ncol=3,byrow=TRUE)
colnames(model_table) <- c("Accuracy","Sensitivity","Specificity")
rownames(model_table) <- c("Logistic regression","XGBoost","K Nearest Neighbours","Naïve Bayes")
model_table <- as.table(model_table)
model_table
```
The `XGBoost` model has the highest `Accuracy` and `Sensitivity` which are `0.6460` and `0.8740` respectively. XGBoost model performs best in classifying households into two groups (switched well or not)


## Additional step

For additional step in the analysis of the water quality data, I will use the Naïve Bayes Classifier to classify house into whether they switched wells or not.
Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Baye’s theorem with strong (naive) independence assumptions between the features or variables. The Naive Bayes algorithm assumes that the occurrence of a particular feature is independent of the occurrence of other features.

```{r}
# Loading package
library(e1071)
library(caTools)
library(caret)

# Splitting data into training and testing datasets
#split <- sample.split(df, SplitRatio = 0.8)
#train_df <- subset(df, split == "TRUE")
#test_df <- subset(df, split == "FALSE")

train_scale <- scale(df_train[, 2:3])
test_scale <- scale(df_test[, 2:3])

# Fitting Naive Bayes Model to the training dataset
#set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(switch_well ~ ., data = df_train)
classifier_cl

# Predicting on test data'
y_pred <- predict(classifier_cl, newdata = df_test)

# Confusion Matrix
cm <- table(df_test$switch_well, y_pred)

# Model Evauation
confusionMatrix(cm)
```

The Naïve Bayes Classifier is accurate  61% of the time.


## Conclusion

This project aimed to determine whether households switched well in Bangladesh by following a study conducted in 2004 on arsenic levels in drinking water. The data we used comprised several variables believed to have influenced a decision of a household to switch well or not. We conducted predictive analytics to investigate how accurately we can predict whether or not a household will change wells based on these environmental factors, particularly arsenic levels and distance to the nearest safe well. 

The dataset used had five variables as listed below.
* An indicator of whether a household switches wells
* The distance (in meters) to the closest known safe well
* The arsenic level of the household’s well
* An indicator of whether any members of the household are involved in community organizations
* The highest education level in the household.

Our analysis used several models to predict whether a household will change wells based on the distance, arsenic level, household involvement in organizations, and highest education level in a household. 


The prediction of our models was accurate between 62% and 65% of the time, with the XGBoost model performing the best. 

Based on these results, we can observe that our models did not do a good job classifying the households on whether they switched wells. The accuracy of about 64% average is not great. So The dataset and the included features (factors) can not be good predictors in their original form. Also, there is a possibility that other factors not in our dataset could influence household decisions, such as economic factors. 






